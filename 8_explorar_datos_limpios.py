import dask
import dask.dataframe as dd
import pandas as pd
from dask.diagnostics import ProgressBar

# Configuramos pandas para que siempre muestre todas las columnas
pd.set_option('display.max_columns', None)


def generar_resumen(ddf: dd.DataFrame):
    """
    Calcula y muestra un resumen completo de la estructura y calidad
    de un Dask DataFrame.
    """
    print("\n------ Resumen del Dataset Final con Caracter√≠sticas Adicionales ------")

    with ProgressBar():
        # Definimos todas las tareas que queremos computar
        total_registros_task = ddf.shape[0]
        nulos_por_columna_task = ddf.isnull().sum()
        estadisticas_total_task = ddf["total"].describe()

        # Ejecutamos las tareas r√°pidas en paralelo
        (
            total_registros,
            nulos_por_columna,
            estadisticas_total,
        ) = dask.compute(
            total_registros_task,
            nulos_por_columna_task,
            estadisticas_total_task,
        )

    total_columnas = len(ddf.columns)

    # 1. Dimensiones
    print(f"\n1. Dimensiones:")
    print(f"   - N√∫mero total de registros: {total_registros:,}")
    print(f"   - N√∫mero total de columnas: {total_columnas}")

    # 2. Tipos de Datos
    print(f"\n2. Columnas y Tipos de Datos:")
    print(ddf.dtypes)

    # 3. Muestra de Datos
    print(f"\n3. Primeras 5 filas de muestra:")
    # mostramos tambi√©n las nuevas columnas
    print(ddf.head()[['estacion', 'total', 'tipo_dia', 'franja_horaria', 'ubicacion']])

    # 4. Valores Nulos
    print(f"\n4. Conteo de Valores Nulos:")
    if nulos_por_columna.sum() > 0:
        print(nulos_por_columna[nulos_por_columna > 0])
    else:
        print("   ‚úÖ No se encontraron valores nulos.")

    # 5. Estad√≠sticas Descriptivas
    print("\n5. Estad√≠sticas de la columna 'total':")
    print(estadisticas_total.round(2))


def main():
    """
    Funci√≥n principal para cargar los datos y ejecutar el resumen.
    """
    # Apunta a la versi√≥n final con las nuevas caracter√≠sticas.
    PARQUET_PATH = "data/dataset_subtes/final_con_features"

    try:
        print(f"üîé Cargando datos desde: {PARQUET_PATH}")
        ddf = dd.read_parquet(PARQUET_PATH)
        generar_resumen(ddf)
    except FileNotFoundError:
        print(f"‚ùå ERROR: No se encontr√≥ el directorio de datos en '{PARQUET_PATH}'.")
        print("   Aseg√∫rate de haber ejecutado todos los scripts de procesamiento primero.")

    print("\n\nAn√°lisis de exploraci√≥n completado.")


if __name__ == "__main__":
    main()